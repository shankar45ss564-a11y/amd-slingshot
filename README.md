# RL-Driven Agentic Project Manager (AMD SlingShot Hackathon)

A simulation-first backend system designed to train reinforcement learning (RL) agents for optimal project management. The system simulates a dynamic environment with tasks, workers, deadlines, and fatigue, exposing this state via Model Context Protocol (MCP) tools for agent interaction.

## ğŸš€ Key Features

*   **Simulation Engine**: Realistic modeling of task progress, worker fatigue, deadlines, and skill matching.
*   **RL-Ready Environment**: dedicated `RLEnvironment` class providing observation vectors and rewards for training agents.
*   **MCP Integration**: Exposes simulation control and state inspection as MCP tools (`simulate_step`, `get_rl_observation`).
*   **FastAPI Backend**: Robust REST API for external interaction and monitoring.
*   **Modular Architecture**: Clean separation of concerns (Simulation, MCP, RL, DB).

## ğŸ“‚ Project Structure

```
app/
â”œâ”€â”€ core/           # Configuration & constants
â”œâ”€â”€ db/             # Pydantic models & in-memory mock database
â”œâ”€â”€ mcp/            # MCP server & tool definitions
â”œâ”€â”€ rl/             # Reinforcement Learning environment & wrappers
â”œâ”€â”€ services/       # Business logic (Simulation, Task assignment)
â”œâ”€â”€ api/            # FastAPI routes
â””â”€â”€ main.py         # Application entrypoint
scripts/
â”œâ”€â”€ run_server.py   # Script to start the FastAPI/MCP server
â””â”€â”€ verify_backend.py # specific script to verify simulation logic
```

## ğŸ› ï¸ Getting Started

### Prerequisites

*   Python 3.10+
*   [uv](https://github.com/astral-sh/uv) (recommended for dependency management)

### Installation

1.  Clone the repository.
2.  Install dependencies:

```bash
# Recommended: using uv (fast Python package manager)
uv sync

# Or using pip
pip install -e .
```

### Running the Server

Start the FastAPI server with MCP mounted:

```bash
uv run scripts/run_server.py
```

The API will be available at `http://localhost:8000`.
MCP endpoint (SSE) is available at `http://localhost:8000/mcp/sse` (or similar depending on FastMCP config).

## ğŸ§  Simulation & RL

### Simulation Logic
The system runs a discrete-time simulation where:
*   **Tasks** have difficulty, deadlines, and required skills.
*   **Workers** have skill levels, efficiency, and fatigue properties.
*   **Time** advances in steps (e.g., 1 hour), updating progress and fatigue.

### Interacting with the Simulation

You can control the simulation using MCP tools or directly via Python scripts.

**Example MCP Tool Usage:**

*   `get_state()`: View all tasks and workers.
*   `assign_task(worker_id, task_id)`: Assign work.
*   `simulate_step(hours=1.0)`: Advance time by 1 hour.
*   `get_rl_observation()`: Get the vectorized state for an RL agent.

### Running the MCP Inspector

To test the MCP integration using the official inspector (note the `-q` flag to silence uv output):

```bash
npx @modelcontextprotocol/inspector uv run -q scripts/run_mcp.py
```

### Verification

Run the included verification script to test the simulation dynamics:

```bash
uv run python -m scripts.verify_backend
```

Or run the comprehensive test script to install dependencies, run tests, and verify the server:

```bash
python scripts/run_and_test.py
```

## ğŸ“š API Documentation

Once the server is running, visit `http://localhost:8000/docs` for the interactive Swagger UI.